{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d244cae8-efb3-4c4f-8911-47426e8c4c08",
   "metadata": {},
   "source": [
    "# Notebook #2 for Trimming of the generated audio with VAD\n",
    "\n",
    "This notebook is designed to extract a segment of audio with just the spoken word in the generated audio recordings (to generate audio recordings, see notebook #1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67c461-f3c3-4ea0-ab39-46afdc5b9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa\n",
    "import soundfile\n",
    "\n",
    "import torch\n",
    "from sgvad import SGVAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46936dc7-4042-4351-92b2-c4d40ff01840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGVAG_for_trimming(SGVAD):\n",
    "    def predict(self, wave: str or torch.Tensor):\n",
    "        if isinstance(wave, str):\n",
    "            wave = self.load_audio(wave)\n",
    "            wave = torch.tensor(wave)\n",
    "        elif isinstance(wave, torch.Tensor):\n",
    "            wave = torch.tensor(wave)\n",
    "        else:\n",
    "            raise ValueError('unvailible typy for \"wave\"')\n",
    "        \n",
    "        wave = wave.reshape(1, -1)\n",
    "        wave_len = torch.tensor([wave.size(-1)]).reshape(1)\n",
    "        processed_signal, processed_signal_len = self.preprocessor(\n",
    "            input_signal=wave, length=wave_len)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mu, _ = self.model(audio_signal=processed_signal, \n",
    "                               length=processed_signal_len)\n",
    "            binary_gates = torch.clamp(mu + 0.5, 0.0, 1.0)\n",
    "            score = binary_gates.sum(dim=1)\n",
    "        \n",
    "        return score >= self.cfg.threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929dda1d-b077-47f1-88af-bca59e8d75bd",
   "metadata": {},
   "source": [
    "## 1. Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42afb02-6999-4b12-b6cd-d20076ddb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"data/Synt-RuSC/raw/\")\n",
    "output_data_path = Path(\"data/Synt-RuSC/interim/\")\n",
    "\n",
    "# check base_dir path\n",
    "assert base_dir.is_dir(), 'path is not exist, check \"base_dir\"'\n",
    "\n",
    "# create output_data_path path\n",
    "output_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "target_words = [\n",
    "    \"yes\", \"no\", \"up\", \"down\", \"left\", \n",
    "    \"right\", \"on\", \"off\", \"stop\", \"go\", \n",
    "    \"zero\", \"one\", \"two\", \"three\", \"four\", \n",
    "    \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n",
    "    \"backward\", \"forward\", \"follow\", \"learn\", \"visual\",\n",
    "    \"grief\", \"dies\", \"over\", \"motto\", \"newer\", \n",
    "    \"rustier\", \"knock\", \"exclude\", \"nails\", \"discord\", \n",
    "    \"harm\", \"blow_off\", \"create\", \"cry\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5663d0-4691-42be-a5c2-79275b6fecf6",
   "metadata": {},
   "source": [
    "## 2. Trimming of the generated audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df4486-a2a1-47b2-b7f2-a27faeead15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init VAD model\n",
    "\n",
    "sgvad_model = SGVAG_for_trimming.init_from_ckpt()\n",
    "\n",
    "sgvad_model.cfg.threshold = 1.1\n",
    "window_in_samples = (sgvad_model.cfg[\"preprocessor\"][\"window_stride\"] * \n",
    "                     sgvad_model.cfg[\"sample_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc395df-17a6-4dae-b68d-c09df03a806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in [\"train\", \"test\", \"validation\"]:\n",
    "    if not os.path.exists(output_data_path / f\"{subset}_good_max_spread\"):\n",
    "        os.mkdir(output_data_path / f\"{subset}_good_max_spread\")\n",
    "    \n",
    "    for word in os.listdir(base_dir / subset):\n",
    "        if word not in target_words:\n",
    "            continue\n",
    "        print(subset, word)\n",
    "        \n",
    "        if not os.path.exists(output_data_path / f\"{subset}_good_max_spread\" / word):\n",
    "            os.mkdir(output_data_path / f\"{subset}_good_max_spread\"/ word)\n",
    "            \n",
    "        for fName in tqdm(os.listdir(base_dir / subset / word)):\n",
    "            if os.path.exists(output_data_path / f\"{subset}_good_max_spread\" / word / fName):\n",
    "                continue\n",
    "                \n",
    "            # load audio\n",
    "            audio = sgvad_model.load_audio(base_dir / subset / word / fName)\n",
    "            \n",
    "            # too long audio filter\n",
    "            if len(audio) / sgvad_model.cfg.sample_rate > 5:\n",
    "                continue\n",
    "                \n",
    "            # we got a vector preds of dimension T\n",
    "            # here T is the number of windows that the audio was split into\n",
    "            preds = sgvad_model.predict(audio)\n",
    "            for i in range(preds.shape[1]-2):\n",
    "                if preds[0, i]:\n",
    "                    if preds[0, i+2]:\n",
    "                        if not preds[0, i+1]:\n",
    "                            preds[0, i+1] = True\n",
    "            \n",
    "            if preds.sum().sum()==0:\n",
    "                shutil.copy(\n",
    "                    base_dir / subset / word / fName, \n",
    "                    output_data_path / f\"{subset}_bad\" / word / fName\n",
    "                )\n",
    "                continue\n",
    "                \n",
    "            speech_windows = np.array_split(\n",
    "                np.arange(len(preds[0])), \n",
    "                np.where(~preds[0])[0]+1\n",
    "            )\n",
    "\n",
    "            # selected the longest continuous sequence of windows \n",
    "            # for which the VAD modelâ€™s score exceeded the threshold\n",
    "            speech_windows_lens = [len(x) for x in speech_windows]\n",
    "            max_window_idx = np.argmax(speech_windows_lens)\n",
    "            max_window = speech_windows[max_window_idx]\n",
    "            \n",
    "            # some additional sequence extension\n",
    "            if word in [\"four\", \"rustier\", \"forward\", \"exclude\", \"above\"]:\n",
    "                musthave_samples = 850 * sgvad_model.cfg.sample_rate  / 1000\n",
    "            else:\n",
    "                musthave_samples = 700 * sgvad_model.cfg.sample_rate  / 1000\n",
    "            \n",
    "            start_sample = int(max_window[0] * window_in_samples)\n",
    "            end_sample = int(max_window[-1] * window_in_samples)\n",
    "            start_ms = start_sample / sgvad_model.cfg.sample_rate * 1000\n",
    "            end_ms = end_sample / sgvad_model.cfg.sample_rate * 1000\n",
    "            \n",
    "            shift = 1\n",
    "            added_on_left = False\n",
    "            while end_sample - start_sample < musthave_samples:\n",
    "                if start_sample == 0 and end_sample >= len(audio)-1:\n",
    "                    break\n",
    "                \n",
    "                if max_window_idx + shift > len(audio)-1 and max_window_idx - shift < 0:\n",
    "                    break\n",
    "                \n",
    "                if not added_on_left:\n",
    "                    if max_window_idx - shift >= 0:\n",
    "                        start_sample = int(speech_windows[max_window_idx - shift][0] * window_in_samples)\n",
    "                    added_on_left = True\n",
    "                else:\n",
    "                    if max_window_idx + shift <= len(audio)-1:\n",
    "                        end_sample = int(speech_windows[max_window_idx + shift][-1] * window_in_samples)\n",
    "                    \n",
    "                    added_on_left = False\n",
    "                    shift += 1\n",
    "            \n",
    "            start_ms = start_sample / sgvad_model.cfg.sample_rate * 1000\n",
    "            end_ms = end_sample / sgvad_model.cfg.sample_rate * 1000\n",
    "\n",
    "            # if the resulting sequence was shorter than 400 ms or\n",
    "            # longer than 1000 ms, the audio was discarded\n",
    "            if 1000 > (end_ms - start_ms) > 400:\n",
    "                soundfile.write(\n",
    "                    output_data_path / f\"{subset}_good_max_spread\" / word / fName, \n",
    "                    audio[start_sample:end_sample], \n",
    "                    samplerate=sgvad_model.cfg.sample_rate\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naumov_Python310 (torch_hf)",
   "language": "python",
   "name": "torch_hf_py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
